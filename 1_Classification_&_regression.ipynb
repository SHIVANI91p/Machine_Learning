{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d7d152c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T04:37:52.288607Z",
     "start_time": "2023-05-31T04:37:33.849515Z"
    },
    "id": "4d7d152c"
   },
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "#!pip install tensorflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Sequential\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f309600",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T08:22:43.780795Z",
     "start_time": "2023-05-30T08:22:43.762381Z"
    },
    "id": "8f309600"
   },
   "outputs": [],
   "source": [
    "#Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7f84611",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T04:38:18.199842Z",
     "start_time": "2023-05-31T04:38:17.086831Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "e7f84611",
    "outputId": "fac1e4ae-517c-4a14-b3b4-1281156732d9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0             1    15634602   Hargrave          619    France  Female   42   \n",
       "1             2    15647311       Hill          608     Spain  Female   41   \n",
       "2             3    15619304       Onio          502    France  Female   42   \n",
       "3             4    15701354       Boni          699    France  Female   39   \n",
       "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0          2       0.00              1          1               1   \n",
       "1          1   83807.86              1          0               1   \n",
       "2          8  159660.80              3          1               0   \n",
       "3          1       0.00              2          0               0   \n",
       "4          2  125510.82              1          1               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9995       5       0.00              2          1               0   \n",
       "9996      10   57369.61              1          1               1   \n",
       "9997       7       0.00              1          0               1   \n",
       "9998       3   75075.31              2          1               0   \n",
       "9999       4  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0           101348.88       1  \n",
       "1           112542.58       0  \n",
       "2           113931.57       1  \n",
       "3            93826.63       0  \n",
       "4            79084.10       0  \n",
       "...               ...     ...  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/aishwaryamate/Datasets/main/Churn_Modelling.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f06f5155",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T04:38:20.349196Z",
     "start_time": "2023-05-31T04:38:20.328842Z"
    },
    "id": "f06f5155"
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['RowNumber','CustomerId','Surname'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88aadb13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T14:52:47.749820Z",
     "start_time": "2023-05-28T14:52:47.731540Z"
    },
    "id": "88aadb13"
   },
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "jV8iAz4CBxh1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jV8iAz4CBxh1",
    "outputId": "92efdcc7-274c-4e01-a0d1-f3647ae086b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore        0\n",
       "Geography          0\n",
       "Gender             0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "913d1b10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T04:38:22.668932Z",
     "start_time": "2023-05-31T04:38:22.634983Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "913d1b10",
    "outputId": "141ddb12-e2e4-428a-9c10-73d9d9f10600"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0             619    France  Female   42       2       0.00              1   \n",
       "1             608     Spain  Female   41       1   83807.86              1   \n",
       "2             502    France  Female   42       8  159660.80              3   \n",
       "3             699    France  Female   39       1       0.00              2   \n",
       "4             850     Spain  Female   43       2  125510.82              1   \n",
       "...           ...       ...     ...  ...     ...        ...            ...   \n",
       "9995          771    France    Male   39       5       0.00              2   \n",
       "9996          516    France    Male   35      10   57369.61              1   \n",
       "9997          709    France  Female   36       7       0.00              1   \n",
       "9998          772   Germany    Male   42       3   75075.31              2   \n",
       "9999          792    France  Female   28       4  130142.79              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0             1               1        101348.88       1  \n",
       "1             0               1        112542.58       0  \n",
       "2             1               0        113931.57       1  \n",
       "3             0               0         93826.63       0  \n",
       "4             1               1         79084.10       0  \n",
       "...         ...             ...              ...     ...  \n",
       "9995          1               0         96270.64       0  \n",
       "9996          1               1        101699.77       0  \n",
       "9997          0               1         42085.58       1  \n",
       "9998          1               0         92888.52       1  \n",
       "9999          1               0         38190.78       0  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "Ur-8Cuy_Cmjn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "Ur-8Cuy_Cmjn",
    "outputId": "91263b0c-e8a3-4924-99d2-50eb6f436cf5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0             619    France  Female   42       2       0.00              1   \n",
       "1             608     Spain  Female   41       1   83807.86              1   \n",
       "2             502    France  Female   42       8  159660.80              3   \n",
       "3             699    France  Female   39       1       0.00              2   \n",
       "4             850     Spain  Female   43       2  125510.82              1   \n",
       "...           ...       ...     ...  ...     ...        ...            ...   \n",
       "9995          771    France    Male   39       5       0.00              2   \n",
       "9996          516    France    Male   35      10   57369.61              1   \n",
       "9997          709    France  Female   36       7       0.00              1   \n",
       "9998          772   Germany    Male   42       3   75075.31              2   \n",
       "9999          792    France  Female   28       4  130142.79              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "0             1               1        101348.88  \n",
       "1             0               1        112542.58  \n",
       "2             1               0        113931.57  \n",
       "3             0               0         93826.63  \n",
       "4             1               1         79084.10  \n",
       "...         ...             ...              ...  \n",
       "9995          1               0         96270.64  \n",
       "9996          1               1        101699.77  \n",
       "9997          0               1         42085.58  \n",
       "9998          1               0         92888.52  \n",
       "9999          1               0         38190.78  \n",
       "\n",
       "[10000 rows x 10 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns = ['Exited'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04e1f6df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T04:38:24.413123Z",
     "start_time": "2023-05-31T04:38:24.344291Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "04e1f6df",
    "outputId": "c0d62573-840a-40f8-b702-6740b476d856"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0             619   42       2       0.00              1          1   \n",
       "1             608   41       1   83807.86              1          0   \n",
       "2             502   42       8  159660.80              3          1   \n",
       "3             699   39       1       0.00              2          0   \n",
       "4             850   43       2  125510.82              1          1   \n",
       "...           ...  ...     ...        ...            ...        ...   \n",
       "9995          771   39       5       0.00              2          1   \n",
       "9996          516   35      10   57369.61              1          1   \n",
       "9997          709   36       7       0.00              1          0   \n",
       "9998          772   42       3   75075.31              2          1   \n",
       "9999          792   28       4  130142.79              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "0                  1        101348.88       1                 1   \n",
       "1                  1        112542.58       0                 0   \n",
       "2                  0        113931.57       1                 1   \n",
       "3                  0         93826.63       0                 1   \n",
       "4                  1         79084.10       0                 0   \n",
       "...              ...              ...     ...               ...   \n",
       "9995               0         96270.64       0                 1   \n",
       "9996               1        101699.77       0                 1   \n",
       "9997               1         42085.58       1                 1   \n",
       "9998               0         92888.52       1                 0   \n",
       "9999               0         38190.78       0                 1   \n",
       "\n",
       "      Geography_Germany  Geography_Spain  Gender_Female  Gender_Male  \n",
       "0                     0                0              1            0  \n",
       "1                     0                1              1            0  \n",
       "2                     0                0              1            0  \n",
       "3                     0                0              1            0  \n",
       "4                     0                1              1            0  \n",
       "...                 ...              ...            ...          ...  \n",
       "9995                  0                0              0            1  \n",
       "9996                  0                0              0            1  \n",
       "9997                  0                0              1            0  \n",
       "9998                  1                0              0            1  \n",
       "9999                  0                0              1            0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(data=df, columns=['Geography','Gender'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LZd1s-pYCc7X",
   "metadata": {
    "id": "LZd1s-pYCc7X"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdfe6448",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T14:55:18.800964Z",
     "start_time": "2023-05-28T14:55:18.776773Z"
    },
    "id": "bdfe6448"
   },
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "DKCVd8Tbcemq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "DKCVd8Tbcemq",
    "outputId": "b7c55af5-ae1b-4336-bcec-4e79a9832214"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0             619   42       2       0.00              1          1   \n",
       "1             608   41       1   83807.86              1          0   \n",
       "2             502   42       8  159660.80              3          1   \n",
       "3             699   39       1       0.00              2          0   \n",
       "4             850   43       2  125510.82              1          1   \n",
       "...           ...  ...     ...        ...            ...        ...   \n",
       "9995          771   39       5       0.00              2          1   \n",
       "9996          516   35      10   57369.61              1          1   \n",
       "9997          709   36       7       0.00              1          0   \n",
       "9998          772   42       3   75075.31              2          1   \n",
       "9999          792   28       4  130142.79              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "0                  1        101348.88       1                 1   \n",
       "1                  1        112542.58       0                 0   \n",
       "2                  0        113931.57       1                 1   \n",
       "3                  0         93826.63       0                 1   \n",
       "4                  1         79084.10       0                 0   \n",
       "...              ...              ...     ...               ...   \n",
       "9995               0         96270.64       0                 1   \n",
       "9996               1        101699.77       0                 1   \n",
       "9997               1         42085.58       1                 1   \n",
       "9998               0         92888.52       1                 0   \n",
       "9999               0         38190.78       0                 1   \n",
       "\n",
       "      Geography_Germany  Geography_Spain  Gender_Female  Gender_Male  \n",
       "0                     0                0              1            0  \n",
       "1                     0                1              1            0  \n",
       "2                     0                0              1            0  \n",
       "3                     0                0              1            0  \n",
       "4                     0                1              1            0  \n",
       "...                 ...              ...            ...          ...  \n",
       "9995                  0                0              0            1  \n",
       "9996                  0                0              0            1  \n",
       "9997                  0                0              1            0  \n",
       "9998                  1                0              0            1  \n",
       "9999                  0                0              1            0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "248d9f70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T04:38:28.024587Z",
     "start_time": "2023-05-31T04:38:28.008081Z"
    },
    "id": "248d9f70"
   },
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "x = df.drop(columns=['Exited'])\n",
    "y = df['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c662393c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T04:38:29.659646Z",
     "start_time": "2023-05-31T04:38:29.621304Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c662393c",
    "outputId": "6e44f863-3d29-442d-b694-8b13512e5d0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.32622142,  0.29351742, -1.04175968, ..., -0.57380915,\n",
       "         1.09598752, -1.09598752],\n",
       "       [-0.44003595,  0.19816383, -1.38753759, ...,  1.74273971,\n",
       "         1.09598752, -1.09598752],\n",
       "       [-1.53679418,  0.29351742,  1.03290776, ..., -0.57380915,\n",
       "         1.09598752, -1.09598752],\n",
       "       ...,\n",
       "       [ 0.60498839, -0.27860412,  0.68712986, ..., -0.57380915,\n",
       "         1.09598752, -1.09598752],\n",
       "       [ 1.25683526,  0.29351742, -0.69598177, ..., -0.57380915,\n",
       "        -0.91241915,  0.91241915],\n",
       "       [ 1.46377078, -1.04143285, -0.35020386, ..., -0.57380915,\n",
       "         1.09598752, -1.09598752]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sc.fit_transform(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c613ddfc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T04:38:31.835861Z",
     "start_time": "2023-05-31T04:38:31.811539Z"
    },
    "id": "c613ddfc"
   },
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ULXjbhCce_5D",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ULXjbhCce_5D",
    "outputId": "53cca885-9801-4053-9a44-5dd54c967c40"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.23310044, -0.94607926, -0.69598177, ..., -0.57380915,\n",
       "        -0.91241915,  0.91241915],\n",
       "       [-0.25379399, -0.94607926, -0.35020386, ..., -0.57380915,\n",
       "         1.09598752, -1.09598752],\n",
       "       [-0.39864885,  0.77028538,  0.34135195, ..., -0.57380915,\n",
       "         1.09598752, -1.09598752],\n",
       "       ...,\n",
       "       [ 0.22215769,  0.5795782 ,  1.37868567, ..., -0.57380915,\n",
       "         1.09598752, -1.09598752],\n",
       "       [ 0.12903671,  0.00745665,  1.03290776, ..., -0.57380915,\n",
       "         1.09598752, -1.09598752],\n",
       "       [ 1.16371428,  0.29351742,  0.34135195, ..., -0.57380915,\n",
       "        -0.91241915,  0.91241915]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89461e22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T04:42:54.422481Z",
     "start_time": "2023-05-31T04:41:51.909124Z"
    },
    "id": "89461e22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\pawar\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\pawar\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\pawar\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\pawar\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "250/250 [==============================] - 11s 18ms/step - loss: 0.6795 - accuracy: 0.5444\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 0.6787 - accuracy: 0.5459\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 0.6779 - accuracy: 0.5471\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.6770 - accuracy: 0.5494\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.6761 - accuracy: 0.5509\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.6752 - accuracy: 0.5523\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.6743 - accuracy: 0.5534\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.6734 - accuracy: 0.5548\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.6724 - accuracy: 0.5565\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.6715 - accuracy: 0.5583\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.6706 - accuracy: 0.5600\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.6696 - accuracy: 0.5614\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.6687 - accuracy: 0.5627\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.6677 - accuracy: 0.5654\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.6668 - accuracy: 0.5670\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.6659 - accuracy: 0.5680\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.6650 - accuracy: 0.5700\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 0.6640 - accuracy: 0.5716\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.6631 - accuracy: 0.5738\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 9s 34ms/step - loss: 0.6622 - accuracy: 0.5765\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.6613 - accuracy: 0.5769\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 0.6604 - accuracy: 0.5780\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 0.6595 - accuracy: 0.5791\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 0.6586 - accuracy: 0.5815\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 0.6577 - accuracy: 0.5828\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.6568 - accuracy: 0.5832\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.6559 - accuracy: 0.5846\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.6550 - accuracy: 0.5849\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.6541 - accuracy: 0.5866\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.6532 - accuracy: 0.5875\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.6524 - accuracy: 0.5893\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.6515 - accuracy: 0.5916\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.6506 - accuracy: 0.5926\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.6498 - accuracy: 0.5947\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 0.6489 - accuracy: 0.5953\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 0.6480 - accuracy: 0.5961\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 0.6472 - accuracy: 0.5970\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 0.6463 - accuracy: 0.5984\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 0.6455 - accuracy: 0.6008\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 0.6446 - accuracy: 0.6024\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 0.6438 - accuracy: 0.6045\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 0.6430 - accuracy: 0.6066\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 0.6422 - accuracy: 0.6090\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 0.6413 - accuracy: 0.6120\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 0.6405 - accuracy: 0.6140\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 0.6397 - accuracy: 0.6156\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 0.6389 - accuracy: 0.6174\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 0.6381 - accuracy: 0.6186\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 0.6373 - accuracy: 0.6200\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 0.6365 - accuracy: 0.6210\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 0.6358 - accuracy: 0.6226\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 0.6350 - accuracy: 0.6245\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 0.6342 - accuracy: 0.6265\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 0.6334 - accuracy: 0.6277\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 0.6327 - accuracy: 0.6279\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 0.6319 - accuracy: 0.6292\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 0.6311 - accuracy: 0.6309\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 0.6304 - accuracy: 0.6327\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 0.6296 - accuracy: 0.6334\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 0.6289 - accuracy: 0.6349\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 0.6281 - accuracy: 0.6357\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 0.6274 - accuracy: 0.6376\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 0.6266 - accuracy: 0.6399\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 0.6259 - accuracy: 0.6409\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 0.6251 - accuracy: 0.6421\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 0.6244 - accuracy: 0.6429\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 0.6237 - accuracy: 0.6442\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 0.6229 - accuracy: 0.6460\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 0.6222 - accuracy: 0.6471\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 0.6215 - accuracy: 0.6494\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 0.6208 - accuracy: 0.6507\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 4s 15ms/step - loss: 0.6200 - accuracy: 0.6526\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 0.6193 - accuracy: 0.6543\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 0.6186 - accuracy: 0.6554\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 0.6179 - accuracy: 0.6570\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 0.6172 - accuracy: 0.6576\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 0.6165 - accuracy: 0.6584\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 0.6158 - accuracy: 0.6603\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 0.6151 - accuracy: 0.6615\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 0.6144 - accuracy: 0.6634\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 0.6137 - accuracy: 0.6644\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 0.6131 - accuracy: 0.6661\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 6s 25ms/step - loss: 0.6124 - accuracy: 0.6676\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 0.6117 - accuracy: 0.6687\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 0.6110 - accuracy: 0.6700\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.6103 - accuracy: 0.6716\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 0.6097 - accuracy: 0.6737\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.6090 - accuracy: 0.6744\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 0.6084 - accuracy: 0.6755\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 0.6077 - accuracy: 0.6764\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 0.6071 - accuracy: 0.6780\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.6064 - accuracy: 0.6786\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.6058 - accuracy: 0.6799\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.6051 - accuracy: 0.6809\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.6045 - accuracy: 0.6824\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.6038 - accuracy: 0.6835\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.6032 - accuracy: 0.6849\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.6026 - accuracy: 0.6858\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 0.6019 - accuracy: 0.6874\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.6013 - accuracy: 0.6890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2a0ef027810>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize model\n",
    "ann = Sequential()\n",
    "\n",
    "#Add hidden layer\n",
    "ann.add(Dense(units=10,activation='relu'))   # units is nothing but no.of neurons , Dense is use to add layer\n",
    "\n",
    "\n",
    "#Add output layer\n",
    "ann.add(Dense(units=1, activation='sigmoid'))   #\n",
    "#Establish the connection between the layers\n",
    "ann.compile(optimizer = 'adadelta',loss='binary_crossentropy',metrics='accuracy')  # adadelta is Gradiant descent,loss is error\n",
    "\n",
    "#Fit the data\n",
    "ann.fit(xtrain,ytrain, epochs=100)  # epochs is no .of Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "AkEgGGF73qPr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AkEgGGF73qPr",
    "outputId": "bd842a50-2076-4b10-d52e-4e77a8b224c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.04014895,  0.77028538, -1.04175968, ..., -0.57380915,\n",
       "        -0.91241915,  0.91241915],\n",
       "       [ 0.3049319 , -0.4693113 , -0.69598177, ..., -0.57380915,\n",
       "        -0.91241915,  0.91241915],\n",
       "       [-1.23673768,  0.29351742, -1.04175968, ..., -0.57380915,\n",
       "         1.09598752, -1.09598752],\n",
       "       ...,\n",
       "       [-0.86425376, -0.4693113 ,  1.72446358, ...,  1.74273971,\n",
       "        -0.91241915,  0.91241915],\n",
       "       [-0.30552787, -0.85072567, -1.04175968, ..., -0.57380915,\n",
       "         1.09598752, -1.09598752],\n",
       "       [ 0.0462625 ,  1.24705333,  1.37868567, ..., -0.57380915,\n",
       "        -0.91241915,  0.91241915]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b626b3a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T04:43:06.646606Z",
     "start_time": "2023-05-31T04:43:05.983361Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b626b3a4",
    "outputId": "59579db3-09e1-4e62-84b2-fc884834a419"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 2s 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.43035877],\n",
       "       [0.42249098],\n",
       "       [0.4743266 ],\n",
       "       ...,\n",
       "       [0.24310835],\n",
       "       [0.43478405],\n",
       "       [0.2816813 ]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred = ann.predict(xtest)\n",
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5xBrkzjxfwXU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5xBrkzjxfwXU",
    "outputId": "214816cd-4321-4124-b7f9-10f9d24a25f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9953    0\n",
       "3850    0\n",
       "4962    0\n",
       "3886    0\n",
       "5437    0\n",
       "       ..\n",
       "3919    0\n",
       "162     0\n",
       "7903    0\n",
       "2242    0\n",
       "2745    0\n",
       "Name: Exited, Length: 2000, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "VAHRaMQ328vx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "VAHRaMQ328vx",
    "outputId": "7ba088ac-13c2-4f04-fe41-11b840331d36"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(ytest,ypred))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2132\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2017\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclassification_report\u001b[39m(\n\u001b[0;32m   2018\u001b[0m     y_true,\n\u001b[0;32m   2019\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2026\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2027\u001b[0m ):\n\u001b[0;32m   2028\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[0;32m   2029\u001b[0m \n\u001b[0;32m   2030\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2129\u001b[0m \u001b[38;5;124;03m    <BLANKLINE>\u001b[39;00m\n\u001b[0;32m   2130\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2132\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m   2134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2135\u001b[0m         labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     95\u001b[0m             type_true, type_pred\n\u001b[0;32m     96\u001b[0m         )\n\u001b[0;32m     97\u001b[0m     )\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    100\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "x_0m5sT74xUm",
   "metadata": {
    "id": "x_0m5sT74xUm"
   },
   "outputs": [],
   "source": [
    "a = 5\n",
    "b = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "vh3vvaz94zTP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vh3vvaz94zTP",
    "outputId": "1c26e43e-d638-475b-a925-d29191ac72d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40cKLl135E8f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "40cKLl135E8f",
    "outputId": "0b1301f2-996d-4090-a6b2-067a35ea250c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "False == 0\n",
    "True == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "rTwEncqh4dya",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rTwEncqh4dya",
    "outputId": "4702ae2f-4b56-4db2-c0c2-208a7e6a5d32"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       ...,\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "990c57d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T04:43:49.140780Z",
     "start_time": "2023-05-31T04:43:49.110669Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "990c57d4",
    "outputId": "bbc3b2b1-8323-4fcd-b07e-76a129d8575b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       ...,\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred = ypred > 0.5\n",
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a88e38b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T04:43:51.333058Z",
     "start_time": "2023-05-31T04:43:51.306327Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9a88e38b",
    "outputId": "1c973577-1402-489b-8d50-c0a34696704a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9953    0\n",
       "3850    0\n",
       "4962    0\n",
       "3886    0\n",
       "5437    0\n",
       "       ..\n",
       "3919    0\n",
       "162     0\n",
       "7903    0\n",
       "2242    0\n",
       "2745    0\n",
       "Name: Exited, Length: 2000, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1266496c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T04:43:53.416793Z",
     "start_time": "2023-05-31T04:43:53.377506Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1266496c",
    "outputId": "3ff0da3b-76a1-4945-df3e-4914e6617568"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.75      0.78      1585\n",
      "           1       0.23      0.28      0.26       415\n",
      "\n",
      "    accuracy                           0.66      2000\n",
      "   macro avg       0.52      0.52      0.52      2000\n",
      "weighted avg       0.68      0.66      0.67      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest,ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5440e2d",
   "metadata": {
    "id": "e5440e2d"
   },
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aba59336",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aba59336",
    "outputId": "3c3b610f-e6ad-4906-f51c-d685aeccdbc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-tuner\n",
      "  Obtaining dependency information for keras-tuner from https://files.pythonhosted.org/packages/2b/39/21f819fcda657c37519cf817ca1cd03a8a025262aad360876d2a971d38b3/keras_tuner-1.4.6-py3-none-any.whl.metadata\n",
      "  Downloading keras_tuner-1.4.6-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: keras in c:\\users\\pawar\\anaconda3\\lib\\site-packages (from keras-tuner) (2.15.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\pawar\\anaconda3\\lib\\site-packages (from keras-tuner) (23.0)\n",
      "Requirement already satisfied: requests in c:\\users\\pawar\\anaconda3\\lib\\site-packages (from keras-tuner) (2.31.0)\n",
      "Collecting kt-legacy (from keras-tuner)\n",
      "  Obtaining dependency information for kt-legacy from https://files.pythonhosted.org/packages/16/53/aca9f36da2516db008017db85a1f3cafaee0efc5fc7a25d94c909651792f/kt_legacy-1.0.5-py3-none-any.whl.metadata\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pawar\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pawar\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pawar\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pawar\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2023.7.22)\n",
      "Downloading keras_tuner-1.4.6-py3-none-any.whl (128 kB)\n",
      "   ---------------------------------------- 0.0/128.9 kB ? eta -:--:--\n",
      "   -------------------------------------- - 122.9/128.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 128.9/128.9 kB 1.5 MB/s eta 0:00:00\n",
      "Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Installing collected packages: kt-legacy, keras-tuner\n",
      "Successfully installed keras-tuner-1.4.6 kt-legacy-1.0.5\n"
     ]
    }
   ],
   "source": [
    "#!pip install -U keras-tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "X77w688Lsiz3",
   "metadata": {
    "id": "X77w688Lsiz3"
   },
   "source": [
    "# **Tuning the ANN Model**\n",
    "- Selecting the best optimizer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6eb23f42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T04:45:08.598648Z",
     "start_time": "2023-05-31T04:45:08.357015Z"
    },
    "id": "6eb23f42"
   },
   "outputs": [],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e8b66583",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T04:59:29.464058Z",
     "start_time": "2023-05-31T04:59:29.445074Z"
    },
    "id": "e8b66583"
   },
   "outputs": [],
   "source": [
    "def optimizer_selection(hp):\n",
    "    #initialize the model\n",
    "    model = Sequential()\n",
    "    #Add hidden layer\n",
    "    model.add(Dense(units=10, activation='relu'))\n",
    "    #Add output layer\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    #Optimizer selection\n",
    "    optim = hp.Choice('optimizer', values = ['sgd','adam','rmsprop'])\n",
    "    model.compile(optimizer=optim, loss = 'binary_crossentropy', metrics = 'accuracy')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4c10ec2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T04:59:30.318665Z",
     "start_time": "2023-05-31T04:59:30.262636Z"
    },
    "id": "d4c10ec2"
   },
   "outputs": [],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    optimizer_selection,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e7de9a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T04:59:41.516685Z",
     "start_time": "2023-05-31T04:59:31.031972Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6e7de9a8",
    "outputId": "132ac939-fcfe-4bb8-cbae-880bb2d3f63f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 00m 24s]\n",
      "val_accuracy: 0.8059999942779541\n",
      "\n",
      "Best val_accuracy So Far: 0.8144999742507935\n",
      "Total elapsed time: 00h 01m 07s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(xtrain,ytrain, epochs = 3, validation_data = (xtest,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "542c21f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T05:00:58.352892Z",
     "start_time": "2023-05-31T05:00:58.339606Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "542c21f4",
    "outputId": "0fee6366-9d20-4bf2-b286-2a2b4ec49a17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer': 'rmsprop'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f37cb98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T05:05:26.696125Z",
     "start_time": "2023-05-31T05:04:05.391103Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4f37cb98",
    "outputId": "df6dbd39-fe25-447a-af8d-20702432bfcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 5s 12ms/step - loss: 0.4226 - accuracy: 0.8217 - val_loss: 0.4136 - val_accuracy: 0.8205\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.4107 - accuracy: 0.8275 - val_loss: 0.4025 - val_accuracy: 0.8285\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 0.4005 - accuracy: 0.8335 - val_loss: 0.3933 - val_accuracy: 0.8370\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3914 - accuracy: 0.8369 - val_loss: 0.3850 - val_accuracy: 0.8425\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 0.3831 - accuracy: 0.8424 - val_loss: 0.3768 - val_accuracy: 0.8460\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 7s 28ms/step - loss: 0.3765 - accuracy: 0.8478 - val_loss: 0.3698 - val_accuracy: 0.8470\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 0.3708 - accuracy: 0.8504 - val_loss: 0.3644 - val_accuracy: 0.8555\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 0.3658 - accuracy: 0.8531 - val_loss: 0.3584 - val_accuracy: 0.8575\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3620 - accuracy: 0.8558 - val_loss: 0.3557 - val_accuracy: 0.8565\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3589 - accuracy: 0.8558 - val_loss: 0.3523 - val_accuracy: 0.8585\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3562 - accuracy: 0.8560 - val_loss: 0.3498 - val_accuracy: 0.8590\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3543 - accuracy: 0.8568 - val_loss: 0.3481 - val_accuracy: 0.8590\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3526 - accuracy: 0.8568 - val_loss: 0.3472 - val_accuracy: 0.8585\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3512 - accuracy: 0.8577 - val_loss: 0.3458 - val_accuracy: 0.8575\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3501 - accuracy: 0.8593 - val_loss: 0.3440 - val_accuracy: 0.8605\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3489 - accuracy: 0.8577 - val_loss: 0.3429 - val_accuracy: 0.8635\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 0.3480 - accuracy: 0.8581 - val_loss: 0.3427 - val_accuracy: 0.8610\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3471 - accuracy: 0.8579 - val_loss: 0.3417 - val_accuracy: 0.8630\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 0.3464 - accuracy: 0.8583 - val_loss: 0.3414 - val_accuracy: 0.8610\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3457 - accuracy: 0.8587 - val_loss: 0.3401 - val_accuracy: 0.8605\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 0.3450 - accuracy: 0.8585 - val_loss: 0.3401 - val_accuracy: 0.8615\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3445 - accuracy: 0.8590 - val_loss: 0.3388 - val_accuracy: 0.8645\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3440 - accuracy: 0.8591 - val_loss: 0.3387 - val_accuracy: 0.8620\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 0.3435 - accuracy: 0.8591 - val_loss: 0.3396 - val_accuracy: 0.8620\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3432 - accuracy: 0.8599 - val_loss: 0.3386 - val_accuracy: 0.8640\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 0.3428 - accuracy: 0.8599 - val_loss: 0.3380 - val_accuracy: 0.8640\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 0.3423 - accuracy: 0.8584 - val_loss: 0.3378 - val_accuracy: 0.8635\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 0.3421 - accuracy: 0.8597 - val_loss: 0.3382 - val_accuracy: 0.8625\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 0.3417 - accuracy: 0.8586 - val_loss: 0.3367 - val_accuracy: 0.8635\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 0.3419 - accuracy: 0.8596 - val_loss: 0.3367 - val_accuracy: 0.8625\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 0.3412 - accuracy: 0.8589 - val_loss: 0.3369 - val_accuracy: 0.8630\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 0.3414 - accuracy: 0.8590 - val_loss: 0.3362 - val_accuracy: 0.8635\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.3412 - accuracy: 0.8599 - val_loss: 0.3362 - val_accuracy: 0.8635\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 0.3409 - accuracy: 0.8604 - val_loss: 0.3369 - val_accuracy: 0.8655\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 0.3408 - accuracy: 0.8605 - val_loss: 0.3369 - val_accuracy: 0.8635\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 0.3407 - accuracy: 0.8596 - val_loss: 0.3358 - val_accuracy: 0.8635\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.3405 - accuracy: 0.8600 - val_loss: 0.3358 - val_accuracy: 0.8615\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.3403 - accuracy: 0.8600 - val_loss: 0.3370 - val_accuracy: 0.8610\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 0.3402 - accuracy: 0.8593 - val_loss: 0.3355 - val_accuracy: 0.8625\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 0.3400 - accuracy: 0.8602 - val_loss: 0.3349 - val_accuracy: 0.8640\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 6s 25ms/step - loss: 0.3399 - accuracy: 0.8596 - val_loss: 0.3350 - val_accuracy: 0.8620\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3398 - accuracy: 0.8600 - val_loss: 0.3356 - val_accuracy: 0.8630\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3398 - accuracy: 0.8595 - val_loss: 0.3352 - val_accuracy: 0.8620\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 6s 25ms/step - loss: 0.3395 - accuracy: 0.8611 - val_loss: 0.3356 - val_accuracy: 0.8625\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 0.3395 - accuracy: 0.8609 - val_loss: 0.3352 - val_accuracy: 0.8610\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 7s 27ms/step - loss: 0.3394 - accuracy: 0.8606 - val_loss: 0.3352 - val_accuracy: 0.8610\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.3391 - accuracy: 0.8608 - val_loss: 0.3353 - val_accuracy: 0.8650\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 0.3391 - accuracy: 0.8600 - val_loss: 0.3354 - val_accuracy: 0.8600\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 0.3389 - accuracy: 0.8606 - val_loss: 0.3342 - val_accuracy: 0.8620\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 0.3388 - accuracy: 0.8614 - val_loss: 0.3345 - val_accuracy: 0.8655\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3387 - accuracy: 0.8620 - val_loss: 0.3347 - val_accuracy: 0.8620\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3388 - accuracy: 0.8616 - val_loss: 0.3344 - val_accuracy: 0.8610\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3386 - accuracy: 0.8605 - val_loss: 0.3347 - val_accuracy: 0.8645\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3388 - accuracy: 0.8612 - val_loss: 0.3353 - val_accuracy: 0.8620\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 0.3386 - accuracy: 0.8612 - val_loss: 0.3349 - val_accuracy: 0.8630\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 0.3382 - accuracy: 0.8625 - val_loss: 0.3350 - val_accuracy: 0.8610\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3380 - accuracy: 0.8608 - val_loss: 0.3373 - val_accuracy: 0.8605\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 0.3380 - accuracy: 0.8611 - val_loss: 0.3344 - val_accuracy: 0.8630\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3380 - accuracy: 0.8625 - val_loss: 0.3355 - val_accuracy: 0.8625\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3380 - accuracy: 0.8618 - val_loss: 0.3359 - val_accuracy: 0.8615\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3379 - accuracy: 0.8615 - val_loss: 0.3339 - val_accuracy: 0.8650\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 0.3378 - accuracy: 0.8625 - val_loss: 0.3342 - val_accuracy: 0.8630\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3377 - accuracy: 0.8630 - val_loss: 0.3358 - val_accuracy: 0.8645\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 0.3376 - accuracy: 0.8616 - val_loss: 0.3347 - val_accuracy: 0.8625\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.3374 - accuracy: 0.8618 - val_loss: 0.3355 - val_accuracy: 0.8615\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3374 - accuracy: 0.8609 - val_loss: 0.3362 - val_accuracy: 0.8610\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 0.3372 - accuracy: 0.8625 - val_loss: 0.3351 - val_accuracy: 0.8645\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 0.3373 - accuracy: 0.8612 - val_loss: 0.3354 - val_accuracy: 0.8625\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 8s 30ms/step - loss: 0.3371 - accuracy: 0.8616 - val_loss: 0.3360 - val_accuracy: 0.8625\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 0.3371 - accuracy: 0.8631 - val_loss: 0.3356 - val_accuracy: 0.8635\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 0.3367 - accuracy: 0.8622 - val_loss: 0.3364 - val_accuracy: 0.8630\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 0.3370 - accuracy: 0.8624 - val_loss: 0.3357 - val_accuracy: 0.8645\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 0.3370 - accuracy: 0.8615 - val_loss: 0.3360 - val_accuracy: 0.8635\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.3369 - accuracy: 0.8614 - val_loss: 0.3355 - val_accuracy: 0.8630\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.3367 - accuracy: 0.8622 - val_loss: 0.3353 - val_accuracy: 0.8620\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 0.3367 - accuracy: 0.8625 - val_loss: 0.3366 - val_accuracy: 0.8610\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 0.3363 - accuracy: 0.8614 - val_loss: 0.3352 - val_accuracy: 0.8635\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 0.3364 - accuracy: 0.8635 - val_loss: 0.3348 - val_accuracy: 0.8650\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3363 - accuracy: 0.8622 - val_loss: 0.3339 - val_accuracy: 0.8640\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 0.3362 - accuracy: 0.8634 - val_loss: 0.3352 - val_accuracy: 0.8615\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 0.3362 - accuracy: 0.8614 - val_loss: 0.3349 - val_accuracy: 0.8625\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 0.3361 - accuracy: 0.8629 - val_loss: 0.3342 - val_accuracy: 0.8645\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3361 - accuracy: 0.8616 - val_loss: 0.3346 - val_accuracy: 0.8625\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 0.3359 - accuracy: 0.8631 - val_loss: 0.3341 - val_accuracy: 0.8615\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 0.3360 - accuracy: 0.8629 - val_loss: 0.3346 - val_accuracy: 0.8615\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 0.3357 - accuracy: 0.8627 - val_loss: 0.3353 - val_accuracy: 0.8595\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 0.3359 - accuracy: 0.8611 - val_loss: 0.3335 - val_accuracy: 0.8645\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 0.3356 - accuracy: 0.8634 - val_loss: 0.3357 - val_accuracy: 0.8630\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 0.3357 - accuracy: 0.8629 - val_loss: 0.3354 - val_accuracy: 0.8640\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3354 - accuracy: 0.8631 - val_loss: 0.3346 - val_accuracy: 0.8650\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 0.3358 - accuracy: 0.8633 - val_loss: 0.3351 - val_accuracy: 0.8640\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 0.3354 - accuracy: 0.8637 - val_loss: 0.3367 - val_accuracy: 0.8620\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3357 - accuracy: 0.8644 - val_loss: 0.3363 - val_accuracy: 0.8630\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 0.3354 - accuracy: 0.8630 - val_loss: 0.3350 - val_accuracy: 0.8630\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3355 - accuracy: 0.8625 - val_loss: 0.3338 - val_accuracy: 0.8635\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3352 - accuracy: 0.8610 - val_loss: 0.3335 - val_accuracy: 0.8620\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 0.3354 - accuracy: 0.8630 - val_loss: 0.3347 - val_accuracy: 0.8630\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3354 - accuracy: 0.8631 - val_loss: 0.3358 - val_accuracy: 0.8640\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3353 - accuracy: 0.8637 - val_loss: 0.3346 - val_accuracy: 0.8630\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 0.3353 - accuracy: 0.8629 - val_loss: 0.3345 - val_accuracy: 0.8660\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2a0f2464090>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tuner.get_best_models(num_models=1)[0]\n",
    "model.fit(xtrain,ytrain, epochs = 100, validation_data = (xtest,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aAfqDdnRkYOa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aAfqDdnRkYOa",
    "outputId": "8b31b072-841c-48a3-a28c-58c97f8105d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 4s 15ms/step - loss: 0.3335 - accuracy: 0.8634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3334701955318451, 0.8633750081062317]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f746f6fe",
   "metadata": {
    "id": "f746f6fe"
   },
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1d242962",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T05:10:59.549930Z",
     "start_time": "2023-05-31T05:10:59.027680Z"
    },
    "id": "1d242962"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>461.527929</td>\n",
       "      <td>999.787558</td>\n",
       "      <td>999.766096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>548.130012</td>\n",
       "      <td>998.861615</td>\n",
       "      <td>1001.042403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>410.297162</td>\n",
       "      <td>1000.070267</td>\n",
       "      <td>998.844015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>540.382220</td>\n",
       "      <td>999.952251</td>\n",
       "      <td>1000.440940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>546.024553</td>\n",
       "      <td>1000.446011</td>\n",
       "      <td>1000.338531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>476.526078</td>\n",
       "      <td>1000.018988</td>\n",
       "      <td>999.672732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>457.313186</td>\n",
       "      <td>998.855379</td>\n",
       "      <td>1000.020026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>456.720993</td>\n",
       "      <td>1001.451646</td>\n",
       "      <td>998.847605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>403.315576</td>\n",
       "      <td>1000.771023</td>\n",
       "      <td>998.562851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>599.367094</td>\n",
       "      <td>999.232244</td>\n",
       "      <td>1001.451407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          price     feature1     feature2\n",
       "0    461.527929   999.787558   999.766096\n",
       "1    548.130012   998.861615  1001.042403\n",
       "2    410.297162  1000.070267   998.844015\n",
       "3    540.382220   999.952251  1000.440940\n",
       "4    546.024553  1000.446011  1000.338531\n",
       "..          ...          ...          ...\n",
       "995  476.526078  1000.018988   999.672732\n",
       "996  457.313186   998.855379  1000.020026\n",
       "997  456.720993  1001.451646   998.847605\n",
       "998  403.315576  1000.771023   998.562851\n",
       "999  599.367094   999.232244  1001.451407\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/aishwaryamate/Datasets/main/Regression.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "959cd081",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T05:12:13.379449Z",
     "start_time": "2023-05-31T05:12:13.362802Z"
    },
    "id": "959cd081"
   },
   "outputs": [],
   "source": [
    "x = df.iloc[:,1:]\n",
    "y = df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ec7a715",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T05:12:25.797571Z",
     "start_time": "2023-05-31T05:12:25.775301Z"
    },
    "id": "4ec7a715"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.23277509, -0.22551031],\n",
       "       [-1.18389307,  1.12100979],\n",
       "       [ 0.05762098, -1.19831827],\n",
       "       ...,\n",
       "       [ 1.47655818, -1.19452982],\n",
       "       [ 0.77742978, -1.49494959],\n",
       "       [-0.80318737,  1.55251428]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sc.fit_transform(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca3873d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T05:12:47.183754Z",
     "start_time": "2023-05-31T05:12:47.173188Z"
    },
    "id": "ca3873d1"
   },
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f4927c5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T05:17:03.198687Z",
     "start_time": "2023-05-31T05:16:49.992960Z"
    },
    "id": "f4927c5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 9s 82ms/step - loss: 255952.4531 - val_loss: 262736.8125\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 1s 26ms/step - loss: 255580.9375 - val_loss: 262324.9062\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 255085.2031 - val_loss: 261717.0156\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 254302.3750 - val_loss: 260693.4531\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 1s 26ms/step - loss: 253042.5469 - val_loss: 259118.3750\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 251123.6250 - val_loss: 256711.4062\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 248238.7031 - val_loss: 253274.6250\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 1s 27ms/step - loss: 244185.2969 - val_loss: 248412.2344\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 238640.6562 - val_loss: 241838.0156\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 231371.7656 - val_loss: 233444.7969\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 222169.0625 - val_loss: 223232.7656\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 20ms/step - loss: 211160.5781 - val_loss: 210930.2656\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 198312.3438 - val_loss: 196753.4062\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 183630.9062 - val_loss: 181226.7344\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 167812.5000 - val_loss: 164062.8750\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 150672.0625 - val_loss: 146287.3750\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 1s 47ms/step - loss: 133032.6562 - val_loss: 128033.2266\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 115225.1562 - val_loss: 109921.2812\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 1s 36ms/step - loss: 97868.6875 - val_loss: 92444.9062\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 19ms/step - loss: 81459.3438 - val_loss: 76144.6484\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 66379.4375 - val_loss: 61666.5859\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 53197.5703 - val_loss: 48940.0703\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 41918.3711 - val_loss: 38387.8633\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 32734.6016 - val_loss: 29846.8242\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 25493.3770 - val_loss: 23211.4453\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 19971.0156 - val_loss: 18263.5859\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 1s 26ms/step - loss: 15909.8291 - val_loss: 14635.1123\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 12945.2275 - val_loss: 12053.6963\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 10851.6660 - val_loss: 10170.0352\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 9323.8721 - val_loss: 8837.6865\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 8219.6826 - val_loss: 7851.7437\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 7401.2500 - val_loss: 7104.3096\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 6780.4102 - val_loss: 6514.5562\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 6277.7437 - val_loss: 6054.3193\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 5870.4302 - val_loss: 5678.5439\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 5523.4360 - val_loss: 5356.9829\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 5222.2993 - val_loss: 5078.3071\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 4954.4814 - val_loss: 4810.1143\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 4708.0654 - val_loss: 4574.8247\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 4485.7295 - val_loss: 4350.8184\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 4268.2803 - val_loss: 4144.6982\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 4068.4395 - val_loss: 3956.3992\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 3878.7803 - val_loss: 3760.0632\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 3696.7175 - val_loss: 3578.4221\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 3522.2844 - val_loss: 3397.8323\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 1s 26ms/step - loss: 3357.9978 - val_loss: 3229.5774\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 3194.4980 - val_loss: 3077.8159\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 3046.2390 - val_loss: 2923.8931\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 1s 26ms/step - loss: 2895.5928 - val_loss: 2778.0828\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 1s 38ms/step - loss: 2755.0881 - val_loss: 2636.4382\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 2621.7883 - val_loss: 2500.6553\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 2490.5623 - val_loss: 2375.7642\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 2368.0005 - val_loss: 2254.8843\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 1s 46ms/step - loss: 2249.4360 - val_loss: 2136.5361\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 1s 38ms/step - loss: 2138.0081 - val_loss: 2032.3392\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 2031.2563 - val_loss: 1926.7089\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 1s 52ms/step - loss: 1930.3326 - val_loss: 1830.5822\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 2s 87ms/step - loss: 1834.1763 - val_loss: 1736.7238\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 1742.0747 - val_loss: 1644.8398\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 1655.2100 - val_loss: 1569.0923\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 1573.1417 - val_loss: 1488.8829\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 1s 51ms/step - loss: 1493.0344 - val_loss: 1415.6635\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 1s 27ms/step - loss: 1418.5571 - val_loss: 1346.6084\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 1349.7517 - val_loss: 1275.6765\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 1s 57ms/step - loss: 1283.5602 - val_loss: 1214.8317\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 1218.8331 - val_loss: 1161.1215\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 1160.4789 - val_loss: 1109.1917\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 1106.9569 - val_loss: 1056.3586\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 1051.0566 - val_loss: 1007.5595\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 1002.8882 - val_loss: 961.1209\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 956.3768 - val_loss: 918.9072\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 911.4440 - val_loss: 879.5651\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 868.2836 - val_loss: 841.4730\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 829.9326 - val_loss: 802.2878\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 790.6785 - val_loss: 768.8340\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 754.9906 - val_loss: 735.7154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 721.1294 - val_loss: 704.6238\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 690.1821 - val_loss: 675.4885\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 2s 78ms/step - loss: 658.0867 - val_loss: 647.6680\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 629.8184 - val_loss: 622.0560\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 602.8819 - val_loss: 595.6160\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 576.3700 - val_loss: 571.8159\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 552.7629 - val_loss: 550.0220\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 529.3229 - val_loss: 528.0519\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 507.6614 - val_loss: 509.7035\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 486.6277 - val_loss: 488.9882\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 466.9020 - val_loss: 471.9067\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 447.9232 - val_loss: 454.8173\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 431.4208 - val_loss: 439.5239\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 414.7918 - val_loss: 423.2107\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 396.7487 - val_loss: 406.6670\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 1s 38ms/step - loss: 382.5868 - val_loss: 394.5816\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 1s 39ms/step - loss: 367.7201 - val_loss: 378.7393\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 354.8338 - val_loss: 366.1727\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 340.7439 - val_loss: 353.1627\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 1s 26ms/step - loss: 328.3548 - val_loss: 342.0923\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 317.3427 - val_loss: 331.0585\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 305.4089 - val_loss: 320.0408\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 294.4130 - val_loss: 309.7937\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 284.0912 - val_loss: 298.9401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2a0f25af6d0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann = Sequential()\n",
    "\n",
    "ann.add(Dense(units=30, activation='relu'))\n",
    "ann.add(Dense(units=20, activation='relu'))\n",
    "\n",
    "ann.add(Dense(units=1))\n",
    "\n",
    "ann.compile(optimizer='adam',loss = 'mse')\n",
    "\n",
    "ann.fit(xtrain,ytrain, epochs = 100, validation_data = (xtest,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7e9b4dc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T05:22:11.475020Z",
     "start_time": "2023-05-31T05:22:11.275152Z"
    },
    "id": "7e9b4dc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[473.13885],\n",
       "       [520.646  ],\n",
       "       [497.74506],\n",
       "       [538.62476],\n",
       "       [656.6293 ],\n",
       "       [339.51575],\n",
       "       [361.48413],\n",
       "       [374.11853],\n",
       "       [731.76056],\n",
       "       [508.7225 ],\n",
       "       [482.5036 ],\n",
       "       [504.10504],\n",
       "       [497.26288],\n",
       "       [361.5774 ],\n",
       "       [542.76373],\n",
       "       [488.07172],\n",
       "       [573.01154],\n",
       "       [544.7128 ],\n",
       "       [484.0946 ],\n",
       "       [494.47516],\n",
       "       [474.34644],\n",
       "       [605.56506],\n",
       "       [439.91968],\n",
       "       [574.5967 ],\n",
       "       [423.02536],\n",
       "       [518.6948 ],\n",
       "       [382.94016],\n",
       "       [498.66318],\n",
       "       [536.7657 ],\n",
       "       [349.7729 ],\n",
       "       [444.357  ],\n",
       "       [642.78   ],\n",
       "       [558.27325],\n",
       "       [537.939  ],\n",
       "       [600.88934],\n",
       "       [554.9038 ],\n",
       "       [409.66113],\n",
       "       [567.1981 ],\n",
       "       [567.24695],\n",
       "       [525.92957],\n",
       "       [420.98364],\n",
       "       [740.1775 ],\n",
       "       [520.9518 ],\n",
       "       [525.7538 ],\n",
       "       [521.8931 ],\n",
       "       [468.856  ],\n",
       "       [531.28253],\n",
       "       [522.025  ],\n",
       "       [580.2261 ],\n",
       "       [464.75604],\n",
       "       [379.5102 ],\n",
       "       [623.6186 ],\n",
       "       [823.52295],\n",
       "       [535.15295],\n",
       "       [667.8827 ],\n",
       "       [549.70715],\n",
       "       [485.97226],\n",
       "       [543.6823 ],\n",
       "       [542.8011 ],\n",
       "       [377.30038],\n",
       "       [645.433  ],\n",
       "       [472.56226],\n",
       "       [484.55087],\n",
       "       [501.3781 ],\n",
       "       [557.6266 ],\n",
       "       [336.38226],\n",
       "       [549.5037 ],\n",
       "       [547.67334],\n",
       "       [439.22894],\n",
       "       [597.1273 ],\n",
       "       [558.60046],\n",
       "       [425.16354],\n",
       "       [458.971  ],\n",
       "       [670.18494],\n",
       "       [401.4181 ],\n",
       "       [543.75446],\n",
       "       [342.62573],\n",
       "       [446.21378],\n",
       "       [600.15594],\n",
       "       [532.7645 ],\n",
       "       [450.0017 ],\n",
       "       [441.33383],\n",
       "       [360.17404],\n",
       "       [475.8855 ],\n",
       "       [395.10626],\n",
       "       [659.74896],\n",
       "       [380.5298 ],\n",
       "       [555.6992 ],\n",
       "       [564.9452 ],\n",
       "       [369.81567],\n",
       "       [410.83105],\n",
       "       [499.34402],\n",
       "       [544.75385],\n",
       "       [556.33105],\n",
       "       [752.7202 ],\n",
       "       [533.4435 ],\n",
       "       [615.7058 ],\n",
       "       [611.1513 ],\n",
       "       [618.2029 ],\n",
       "       [537.82776],\n",
       "       [504.271  ],\n",
       "       [521.07465],\n",
       "       [577.6212 ],\n",
       "       [434.33948],\n",
       "       [606.0454 ],\n",
       "       [416.6762 ],\n",
       "       [361.3963 ],\n",
       "       [430.64224],\n",
       "       [411.07977],\n",
       "       [485.61914],\n",
       "       [488.6975 ],\n",
       "       [408.23135],\n",
       "       [476.69315],\n",
       "       [412.04547],\n",
       "       [321.87863],\n",
       "       [591.5365 ],\n",
       "       [490.46234],\n",
       "       [391.38916],\n",
       "       [416.56757],\n",
       "       [567.7191 ],\n",
       "       [475.4768 ],\n",
       "       [453.16537],\n",
       "       [530.34973],\n",
       "       [534.43933],\n",
       "       [562.5079 ],\n",
       "       [498.91443],\n",
       "       [510.70825],\n",
       "       [384.76788],\n",
       "       [560.4373 ],\n",
       "       [580.27496],\n",
       "       [586.36566],\n",
       "       [434.92725],\n",
       "       [554.9638 ],\n",
       "       [393.09924],\n",
       "       [472.864  ],\n",
       "       [644.03925],\n",
       "       [642.57166],\n",
       "       [499.72778],\n",
       "       [602.74976],\n",
       "       [599.53674],\n",
       "       [569.84906],\n",
       "       [461.50665],\n",
       "       [664.1015 ],\n",
       "       [355.99652],\n",
       "       [481.54633],\n",
       "       [534.22833],\n",
       "       [525.3271 ],\n",
       "       [573.3969 ],\n",
       "       [640.3316 ],\n",
       "       [491.65118],\n",
       "       [479.0377 ],\n",
       "       [495.24075],\n",
       "       [359.05203],\n",
       "       [476.02982],\n",
       "       [546.3265 ],\n",
       "       [455.94788],\n",
       "       [593.9404 ],\n",
       "       [565.38684],\n",
       "       [454.9685 ],\n",
       "       [441.56738],\n",
       "       [451.49078],\n",
       "       [535.86804],\n",
       "       [387.5274 ],\n",
       "       [503.9136 ],\n",
       "       [464.18546],\n",
       "       [355.34503],\n",
       "       [534.6178 ],\n",
       "       [396.76474],\n",
       "       [616.4275 ],\n",
       "       [669.1212 ],\n",
       "       [414.80182],\n",
       "       [460.9609 ],\n",
       "       [491.9168 ],\n",
       "       [455.21436],\n",
       "       [400.2444 ],\n",
       "       [615.10114],\n",
       "       [516.7192 ],\n",
       "       [638.7949 ],\n",
       "       [335.93063],\n",
       "       [436.78598],\n",
       "       [457.10822],\n",
       "       [329.06638],\n",
       "       [383.37933],\n",
       "       [550.26465],\n",
       "       [499.56232],\n",
       "       [497.7438 ],\n",
       "       [472.95602],\n",
       "       [505.0296 ],\n",
       "       [509.0422 ],\n",
       "       [361.47894],\n",
       "       [447.33682],\n",
       "       [510.1641 ],\n",
       "       [498.5631 ],\n",
       "       [545.43225],\n",
       "       [446.79694],\n",
       "       [450.8828 ],\n",
       "       [578.24146],\n",
       "       [482.96707],\n",
       "       [505.92426],\n",
       "       [457.88095]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp = ann.predict(xtest)\n",
    "yp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "be1e4bc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T05:21:46.695724Z",
     "start_time": "2023-05-31T05:21:46.676048Z"
    },
    "id": "be1e4bc0"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "056cbe96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T05:23:02.553135Z",
     "start_time": "2023-05-31T05:23:02.536120Z"
    },
    "id": "056cbe96"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9625969238867474"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(ytest,yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ef050f",
   "metadata": {
    "id": "e7ef050f"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
